{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 00:40:44.635465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-10 00:40:44.635493: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[   INFO   ] MusicExtractorSVM: no classifier models were configured by default\n",
      "2023-06-10 00:40:45.075810: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-10 00:40:45.076564: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-10 00:40:45.076582: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-10 00:40:45.076602: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (neeraj-HP-Laptop): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new songs to extract\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data.OpenL3_embeddings import EmbeddingsOpenL3\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from essentia.standard import MonoLoader, TensorflowPredict2D, TensorflowPredictEffnetDiscogs\n",
    "\n",
    "from main.choices import genre_weightage, tags_weightage, instrument_weightage, feature_weights, mdata_outliers, normalizing_factor, balancing_factor, normalizing_factor_meta\n",
    "from pipeline_code import embedding_model_weights_dsg, embedding_model_weights_l3, all_columns_to_drop, rename_labels\n",
    "from unidecode import unidecode\n",
    "from main import choices\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "import numpy as np\n",
    "import music_tag\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/all_classifiers_and_metadata/\"\n",
    "song_path = 'media/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(all_songs, df_extract=None, single_file=None):\n",
    "    column_labels = ['song name']\n",
    "    rows = []\n",
    "    flag = True\n",
    "    with open('data/weights_metadata.json') as json_file:\n",
    "        model_weights_metadata = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "    for song in all_songs:\n",
    "        extractor = EmbeddingsOpenL3(embedding_model_weights_l3)\n",
    "        embeddings_l3 = extractor.compute(song_path + song)\n",
    "\n",
    "        audio = MonoLoader(filename=song_path+song, sampleRate=44100, resampleQuality=4)()\n",
    "        embedding_model = TensorflowPredictEffnetDiscogs(graphFilename=embedding_model_weights_dsg, output=\"PartitionedCall:1\")\n",
    "        embeddings_dsg = embedding_model(audio)\n",
    "\n",
    "        classification_models = {}\n",
    "        for key in model_weights_metadata:\n",
    "            model_type = model_weights_metadata[key][0]\n",
    "            file_name = model_weights_metadata[key][1]\n",
    "\n",
    "            weight_file = path + file_name + \".pb\"\n",
    "            mdata_file = path + file_name + \".json\"\n",
    "\n",
    "            metadata = json.load(open(mdata_file, 'r'))\n",
    "            input_ = metadata['schema']['inputs'][0]['name']\n",
    "            output = metadata['schema']['outputs'][0]['name']\n",
    "            classes = metadata['classes']\n",
    "\n",
    "            model = TensorflowPredict2D(graphFilename=weight_file, output=output, input=input_)\n",
    "            \n",
    "            classification_models[key] = [model, model_type, classes]\n",
    "            \n",
    "        scores = [song] if single_file else [df_extract[df_extract['file_path'] == song]['song name'].values[0]]\n",
    "\n",
    "        for key in classification_models:\n",
    "            model = classification_models[key][0]\n",
    "            model_type = classification_models[key][1]\n",
    "            classes = classification_models[key][2]\n",
    "\n",
    "            if model_type == \"openl3\":\n",
    "                predictions = np.mean(model(embeddings_l3), axis=0)\n",
    "            else:\n",
    "                predictions = np.mean(model(embeddings_dsg), axis=0)\n",
    "\n",
    "            if flag:\n",
    "                for i in range(0, len(predictions)):\n",
    "                    label = str(key) + \"_\" + str(classes[i])\n",
    "                    column_labels.append(label)\n",
    "        \n",
    "            for i in range(0, len(predictions)):\n",
    "                scores.append(predictions[i])\n",
    "                \n",
    "        flag = False\n",
    "        rows.append(scores)\n",
    "    return column_labels, rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/songs_db.csv')\n",
    "df_features = pd.read_csv('data/song_dataset_final.csv')\n",
    "meta_df = pd.read_csv('data/metadata.csv')\n",
    "file_path = 'uploads/temp_neeraj.m4a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/openl3-music-mel128-emb512-3.pb`\n",
      "2023-06-10 00:40:51.208047: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2095965000 Hz\n",
      "2023-06-10 00:40:51.495872: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 391249920 exceeds 10% of free system memory.\n",
      "2023-06-10 00:40:51.741712: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 391249920 exceeds 10% of free system memory.\n",
      "2023-06-10 00:40:52.129860: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 401356800 exceeds 10% of free system memory.\n",
      "2023-06-10 00:40:52.273022: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 401356800 exceeds 10% of free system memory.\n",
      "2023-06-10 00:40:52.435766: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 391249920 exceeds 10% of free system memory.\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/discogs-effnet-bs64-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/danceability-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_acoustic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_aggressive-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_electronic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_happy-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_party-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_relaxed-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_sad-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/tonal_atonal-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/gender-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/voice_instrumental-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/engagement_regression-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/nsynth_reverb-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_instrument-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_genre-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_top50tags-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/danceability-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_acoustic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_aggressive-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_electronic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_happy-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_party-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_relaxed-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_sad-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/tonal_atonal-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/gender-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/voice_instrumental-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/engagement_regression-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/nsynth_reverb-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_instrument-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_genre-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_top50tags-discogs-effnet-1.pb`\n"
     ]
    }
   ],
   "source": [
    "column_labels, rows = extract_all_features([file_path], single_file=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song name</th>\n",
       "      <th>danceability_danceable</th>\n",
       "      <th>danceability_not_danceable</th>\n",
       "      <th>mood_acoustic_acoustic</th>\n",
       "      <th>mood_acoustic_non_acoustic</th>\n",
       "      <th>mood_aggressive_aggressive</th>\n",
       "      <th>mood_aggressive_not_aggressive</th>\n",
       "      <th>mood_electronic_electronic</th>\n",
       "      <th>mood_electronic_non_electronic</th>\n",
       "      <th>mood_happy_happy</th>\n",
       "      <th>...</th>\n",
       "      <th>Tag_piano</th>\n",
       "      <th>Tag_strings</th>\n",
       "      <th>Tag_synthesizer</th>\n",
       "      <th>Tag_violin</th>\n",
       "      <th>Tag_voice</th>\n",
       "      <th>Tag_emotional</th>\n",
       "      <th>Tag_energetic</th>\n",
       "      <th>Tag_film</th>\n",
       "      <th>Tag_happy</th>\n",
       "      <th>Tag_relaxing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uploads/temp_neeraj.m4a</td>\n",
       "      <td>0.342031</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.033019</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>0.397094</td>\n",
       "      <td>0.481588</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>0.044799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03164</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.245114</td>\n",
       "      <td>0.009679</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.034947</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.021609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 song name  danceability_danceable   \n",
       "0  uploads/temp_neeraj.m4a                0.342031  \\\n",
       "\n",
       "   danceability_not_danceable  mood_acoustic_acoustic   \n",
       "0                    0.657969                0.033019  \\\n",
       "\n",
       "   mood_acoustic_non_acoustic  mood_aggressive_aggressive   \n",
       "0                    0.966981                    0.602906  \\\n",
       "\n",
       "   mood_aggressive_not_aggressive  mood_electronic_electronic   \n",
       "0                        0.397094                    0.481588  \\\n",
       "\n",
       "   mood_electronic_non_electronic  mood_happy_happy  ...  Tag_piano   \n",
       "0                        0.518411          0.044799  ...    0.03164  \\\n",
       "\n",
       "   Tag_strings  Tag_synthesizer  Tag_violin  Tag_voice  Tag_emotional   \n",
       "0     0.014006         0.245114    0.009679   0.007887       0.012963  \\\n",
       "\n",
       "   Tag_energetic  Tag_film  Tag_happy  Tag_relaxing  \n",
       "0       0.005592  0.034947   0.004477      0.021609  \n",
       "\n",
       "[1 rows x 203 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(rows, columns=column_labels)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(columns=all_columns_to_drop, inplace=True)\n",
    "new_df.rename(columns=rename_labels, inplace=True)\n",
    "\n",
    "genre_columns = [col for col in new_df.columns if col.startswith(\"Genre\")]\n",
    "tag_columns = [col for col in new_df.columns if col.startswith(\"Tag\")]\n",
    "\n",
    "genre_data = new_df[genre_columns].T\n",
    "tag_data = new_df[tag_columns].T\n",
    "\n",
    "top_genres, top_tags = [], []\n",
    "for col in genre_data.columns:\n",
    "    temp1 = genre_data[col].nlargest(3).index.to_list()\n",
    "    temp2 = tag_data[col].nlargest(5).index.to_list()\n",
    "    top_genres.append(temp1)\n",
    "    top_tags.append(temp2)\n",
    "\n",
    "new_df['top_genres'] = top_genres\n",
    "new_df['top_tags'] = top_tags\n",
    "\n",
    "updated_dataframe = pd.concat([df_features, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "audio_file = music_tag.load_file(song_path + file_path)\n",
    "\n",
    "temp.append(file_path)\n",
    "temp.append(str(audio_file['artist']))\n",
    "temp.append(str(audio_file['album']))\n",
    "temp.append(int(audio_file['tracknumber']))\n",
    "temp.append(str(audio_file['albumartist']))\n",
    "temp.append(int(audio_file['year']))\n",
    "\n",
    "temp_df = pd.DataFrame([temp], columns=meta_df.columns)\n",
    "meta_df = pd.concat([meta_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.DataFrame([[df['ID'].max() + 500, file_path, None]], columns=df.columns)], ignore_index=True)\n",
    "df['year'] = meta_df['year']\n",
    "merged_df = pd.merge(df, updated_dataframe, on='song name', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_columns = [col for col in merged_df.columns if col.startswith(\"Genre\")]\n",
    "tag_columns = [col for col in merged_df.columns if col.startswith(\"Tag\")]\n",
    "instrument_columns = [col for col in merged_df.columns if col.startswith(\"Instrument\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df.iloc[:, 3:-2].copy()\n",
    "X['year'] = X['year'].replace(0, np.nan).fillna(X['year'].median())\n",
    "minmax = MinMaxScaler(feature_range=(0,1))\n",
    "X.iloc[:,:14] = minmax.fit_transform(X.iloc[:,:14])\n",
    "\n",
    "X['voice_male'] = (1 - X['voice_female']) * X['overall_voice']\n",
    "X['voice_female'] = X['voice_female'] * X['overall_voice']\n",
    "\n",
    "instrument_weightage = choices.instrument_weightage\n",
    "feature_weights = choices.feature_weights\n",
    "balancing_factor = choices.balancing_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in feature_weights:\n",
    "    X[key] = X[key] * feature_weights[key]\n",
    "for col in genre_columns:\n",
    "    X[col] = X[col] * genre_weightage\n",
    "for col in instrument_columns:\n",
    "    X[col] = X[col] * instrument_weightage\n",
    "for col in tag_columns:\n",
    "    X[col] = X[col] * tags_weightage\n",
    "\n",
    "df_cosine = pd.DataFrame(cosine_similarity(X, dense_output=True))\n",
    "df_cosine = df_cosine.applymap(lambda x: np.power(x, normalizing_factor))\n",
    "indices = pd.Series(merged_df.index, index = merged_df['song name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    return unidecode(re.sub(r'[^\\w\\s\\,]', '', text.lower())) if str(text) != 'nan' else ''\n",
    "\n",
    "def remove_outliers_and_extra_space(text):\n",
    "    for substring in mdata_outliers:\n",
    "        text = text.replace(substring, '')\n",
    "    clean_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return clean_text\n",
    "\n",
    "artists = meta_df['artist'].apply(lambda x: remove_punct(x).split(', '))\n",
    "albums = meta_df['album'].apply(lambda x: remove_punct(x).split(', '))\n",
    "album_artist = meta_df['album artist'].apply(lambda x: remove_punct(x).split(', '))\n",
    "\n",
    "meta_df['artists_album'] = artists + album_artist + albums\n",
    "meta_df['artists_album'] = meta_df['artists_album'].apply(lambda x: [remove_outliers_and_extra_space(i) for i in x])\n",
    "meta_df['artists_album'] = meta_df['artists_album'].apply(lambda x: list(set(x)))\n",
    "meta_df['artists_album_final'] = meta_df['artists_album'].apply(lambda x: \" \".join([text.replace(\" \", \"_\") for text in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = \"english\")\n",
    "tfidf_matrix = tfidf.fit_transform(meta_df['artists_album_final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine_meta = pd.DataFrame(cosine_similarity(tfidf_matrix, tfidf_matrix))\n",
    "df_cosine_meta = df_cosine_meta.applymap(lambda x: np.power(x, normalizing_factor_meta) * balancing_factor)\n",
    "resultant_cosine = df_cosine.add(df_cosine_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = indices[file_path]\n",
    "similarity_scores = list(enumerate(resultant_cosine[index]))\n",
    "similarity_scores = sorted(similarity_scores, key = lambda x: x[1],reverse = True)\n",
    "similarity_scores = similarity_scores[1:16]\n",
    "res_indices = [i[0] for i in similarity_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "similars = merged_df['ID'].iloc[res_indices[:]].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>song name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>year</th>\n",
       "      <th>sort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1777</td>\n",
       "      <td>Ready Steady Go (Korean Style) - Paul Oakenfold</td>\n",
       "      <td>audio/Ready_Steady_Go_Korean_Style_-_Paul_Oake...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1875</td>\n",
       "      <td>Sadda Dil Vi Tu (Ga Ga Ga Ganpati) - Sachin-Ji...</td>\n",
       "      <td>audio/Sadda_Dil_Vi_Tu_Ga_Ga_Ga_Ganpati_-_Sachi...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1892</td>\n",
       "      <td>Aaluma Doluma - Anirudh Ravichander, Badshah</td>\n",
       "      <td>audio/Aaluma_Doluma_-_Anirudh_Ravichander_Bads...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1805</td>\n",
       "      <td>Naatu Naatu - Rahul Sipligunj, Kaala Bhairava,...</td>\n",
       "      <td>audio/Naatu_Naatu_-_Rahul_Sipligunj_Kaala_Bhai...</td>\n",
       "      <td>2021</td>\n",
       "      <td>1805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1877</td>\n",
       "      <td>Thunder - Imagine Dragons</td>\n",
       "      <td>audio/Thunder_-_Imagine_Dragons.m4a</td>\n",
       "      <td>2017</td>\n",
       "      <td>1877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1865</td>\n",
       "      <td>Vaathi Coming - Anirudh Ravichander, Gana Bala...</td>\n",
       "      <td>audio/Vaathi_Coming_-_Anirudh_Ravichander_Gana...</td>\n",
       "      <td>2020</td>\n",
       "      <td>1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1738</td>\n",
       "      <td>Warrior - Aurora</td>\n",
       "      <td>audio/Warrior_-_Aurora.m4a</td>\n",
       "      <td>2020</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1749</td>\n",
       "      <td>Invisible - Julius Dreisig &amp; Zeus X Crona</td>\n",
       "      <td>audio/Invisible_-_Julius_Dreisig__Zeus_X_Crona...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1905</td>\n",
       "      <td>Radioactive - Imagine Dragons</td>\n",
       "      <td>audio/Radioactive_-_Imagine_Dragons.m4a</td>\n",
       "      <td>2012</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1895</td>\n",
       "      <td>I Don't Do Personals - Ramin Djawadi</td>\n",
       "      <td>audio/I_Dont_Do_Personals_-_Ramin_Djawadi.m4a</td>\n",
       "      <td>2023</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1891</td>\n",
       "      <td>Pistah - Rajesh Murugesan, Shabareesh Varma</td>\n",
       "      <td>audio/Pistah_-_Rajesh_Murugesan_Shabareesh_Var...</td>\n",
       "      <td>2010</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1722</td>\n",
       "      <td>cotton candy - Iris</td>\n",
       "      <td>audio/cotton_candy_-_Iris.m4a</td>\n",
       "      <td>2022</td>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1901</td>\n",
       "      <td>Vertigo (Spitfya Remix) - Rob Gasser &amp; Laura B...</td>\n",
       "      <td>audio/Vertigo_Spitfya_Remix_-_Rob_Gasser__Laur...</td>\n",
       "      <td>2016</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1744</td>\n",
       "      <td>Dilliwaali Girlfriend - Pritam, Arijit Singh, ...</td>\n",
       "      <td>audio/Dilliwaali_Girlfriend_-_Pritam_Arijit_Si...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1763</td>\n",
       "      <td>Ignite - Alan Walker, Julie Bergan, K-391</td>\n",
       "      <td>audio/Ignite_-_Alan_Walker_Julie_Bergan_K-391.m4a</td>\n",
       "      <td>2018</td>\n",
       "      <td>1763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                          song name   \n",
       "134  1777    Ready Steady Go (Korean Style) - Paul Oakenfold  \\\n",
       "140  1875  Sadda Dil Vi Tu (Ga Ga Ga Ganpati) - Sachin-Ji...   \n",
       "1    1892       Aaluma Doluma - Anirudh Ravichander, Badshah   \n",
       "105  1805  Naatu Naatu - Rahul Sipligunj, Kaala Bhairava,...   \n",
       "163  1877                          Thunder - Imagine Dragons   \n",
       "176  1865  Vaathi Coming - Anirudh Ravichander, Gana Bala...   \n",
       "179  1738                                   Warrior - Aurora   \n",
       "68   1749          Invisible - Julius Dreisig & Zeus X Crona   \n",
       "133  1905                      Radioactive - Imagine Dragons   \n",
       "61   1895               I Don't Do Personals - Ramin Djawadi   \n",
       "126  1891        Pistah - Rajesh Murugesan, Shabareesh Varma   \n",
       "184  1722                                cotton candy - Iris   \n",
       "177  1901  Vertigo (Spitfya Remix) - Rob Gasser & Laura B...   \n",
       "35   1744  Dilliwaali Girlfriend - Pritam, Arijit Singh, ...   \n",
       "63   1763          Ignite - Alan Walker, Julie Bergan, K-391   \n",
       "\n",
       "                                             file_path  year  sort  \n",
       "134  audio/Ready_Steady_Go_Korean_Style_-_Paul_Oake...  2002  1777  \n",
       "140  audio/Sadda_Dil_Vi_Tu_Ga_Ga_Ga_Ganpati_-_Sachi...  2013  1875  \n",
       "1    audio/Aaluma_Doluma_-_Anirudh_Ravichander_Bads...  2015  1892  \n",
       "105  audio/Naatu_Naatu_-_Rahul_Sipligunj_Kaala_Bhai...  2021  1805  \n",
       "163                audio/Thunder_-_Imagine_Dragons.m4a  2017  1877  \n",
       "176  audio/Vaathi_Coming_-_Anirudh_Ravichander_Gana...  2020  1865  \n",
       "179                         audio/Warrior_-_Aurora.m4a  2020  1738  \n",
       "68   audio/Invisible_-_Julius_Dreisig__Zeus_X_Crona...  2018  1749  \n",
       "133            audio/Radioactive_-_Imagine_Dragons.m4a  2012  1905  \n",
       "61       audio/I_Dont_Do_Personals_-_Ramin_Djawadi.m4a  2023  1895  \n",
       "126  audio/Pistah_-_Rajesh_Murugesan_Shabareesh_Var...  2010  1891  \n",
       "184                      audio/cotton_candy_-_Iris.m4a  2022  1722  \n",
       "177  audio/Vertigo_Spitfya_Remix_-_Rob_Gasser__Laur...  2016  1901  \n",
       "35   audio/Dilliwaali_Girlfriend_-_Pritam_Arijit_Si...  2017  1744  \n",
       "63   audio/Ignite_-_Alan_Walker_Julie_Bergan_K-391.m4a  2018  1763  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sort'] = pd.Categorical(df['ID'], categories=similars, ordered=True)\n",
    "df_sorted = df.sort_values('sort')\n",
    "df_sorted[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_songs_id(request, id):\n",
    "    df = pd.read_csv('data/songs_db.csv')\n",
    "    df_features = pd.read_csv('data/song_dataset_final.csv')\n",
    "    meta_df = pd.read_csv('data/metadata.csv')\n",
    "    df['year'] = meta_df['year']\n",
    "    merged_df = pd.merge(df, df_features, on='song name', how='inner')\n",
    "    \n",
    "    genre_columns = [col for col in merged_df.columns if col.startswith(\"Genre\")]\n",
    "    tag_columns = [col for col in merged_df.columns if col.startswith(\"Tag\")]\n",
    "    instrument_columns = [col for col in merged_df.columns if col.startswith(\"Instrument\")]\n",
    "    \n",
    "    X = merged_df.iloc[:, 3:-2].copy()\n",
    "    X['year'] = X['year'].replace(0, np.nan).fillna(X['year'].median())\n",
    "    minmax = MinMaxScaler(feature_range=(0,1))\n",
    "    X.iloc[:,:14] = minmax.fit_transform(X.iloc[:,:14])\n",
    "\n",
    "    X['voice_male'] = (1 - X['voice_female']) * X['overall_voice']\n",
    "    X['voice_female'] = X['voice_female'] * X['overall_voice']\n",
    "\n",
    "    instrument_weightage = choices.instrument_weightage\n",
    "    feature_weights = choices.feature_weights\n",
    "    balancing_factor = choices.balancing_factor\n",
    "\n",
    "    if request.user.is_authenticated:\n",
    "        pref = request.user.preference\n",
    "        if pref:\n",
    "            feature_weights['Engagement'] = pref.engagement\n",
    "            feature_weights['danceability'] = pref.danceability\n",
    "            feature_weights['mood_acoustic'] = pref.acoustics\n",
    "            feature_weights['mood_aggressive'] = pref.aggressive\n",
    "            feature_weights['mood_happy'] = pref.happy\n",
    "            feature_weights['mood_party'] = pref.party\n",
    "            feature_weights['mood_relaxed'] = pref.relaxed\n",
    "            feature_weights['mood_sad'] = pref.sad\n",
    "            feature_weights['tonal'] = pref.tonality\n",
    "            feature_weights['Reverb_wet'] = pref.reverb\n",
    "            feature_weights['voice_female'] = pref.gender\n",
    "            feature_weights['voice_male'] = pref.gender\n",
    "            feature_weights['overall_voice'] = pref.voice\n",
    "            feature_weights['year'] = pref.year\n",
    "            instrument_weightage = pref.instrument\n",
    "            balancing_factor = pref.metadata\n",
    "\n",
    "    for key in feature_weights:\n",
    "        X[key] = X[key] * feature_weights[key]\n",
    "    for col in genre_columns:\n",
    "        X[col] = X[col] * genre_weightage\n",
    "    for col in instrument_columns:\n",
    "        X[col] = X[col] * instrument_weightage\n",
    "    for col in tag_columns:\n",
    "        X[col] = X[col] * tags_weightage\n",
    "\n",
    "    df_cosine = pd.DataFrame(cosine_similarity(X, dense_output=True))\n",
    "    df_cosine = df_cosine.applymap(lambda x: np.power(x, normalizing_factor))\n",
    "    indices = pd.Series(merged_df.index, index = merged_df['ID'])\n",
    "\n",
    "    def remove_punct(text):\n",
    "        return unidecode(re.sub(r'[^\\w\\s\\,]', '', text.lower())) if str(text) != 'nan' else ''\n",
    "\n",
    "    def remove_outliers_and_extra_space(text):\n",
    "        for substring in mdata_outliers:\n",
    "            text = text.replace(substring, '')\n",
    "        clean_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return clean_text\n",
    "    \n",
    "    artists = meta_df['artist'].apply(lambda x: remove_punct(x).split(', '))\n",
    "    albums = meta_df['album'].apply(lambda x: remove_punct(x).split(', '))\n",
    "    album_artist = meta_df['album artist'].apply(lambda x: remove_punct(x).split(', '))\n",
    "    \n",
    "    meta_df['artists_album'] = artists + album_artist + albums\n",
    "    meta_df['artists_album'] = meta_df['artists_album'].apply(lambda x: [remove_outliers_and_extra_space(i) for i in x])\n",
    "    meta_df['artists_album'] = meta_df['artists_album'].apply(lambda x: list(set(x)))\n",
    "    meta_df['artists_album_final'] = meta_df['artists_album'].apply(lambda x: \" \".join([text.replace(\" \", \"_\") for text in x]))\n",
    "\n",
    "    tfidf = TfidfVectorizer(stop_words = \"english\")\n",
    "    tfidf_matrix = tfidf.fit_transform(meta_df['artists_album_final'])\n",
    "\n",
    "    df_cosine_meta = pd.DataFrame(cosine_similarity(tfidf_matrix, tfidf_matrix))\n",
    "    df_cosine_meta = df_cosine_meta.applymap(lambda x: np.power(x, normalizing_factor_meta) * balancing_factor)\n",
    "    resultant_cosine = df_cosine.add(df_cosine_meta)\n",
    "\n",
    "    index = indices[id]\n",
    "    similarity_scores = list(enumerate(resultant_cosine[index]))\n",
    "    similarity_scores = sorted(similarity_scores, key = lambda x: x[1],reverse = True)\n",
    "    similarity_scores = similarity_scores[1:16]\n",
    "    res_indices = [i[0] for i in similarity_scores]\n",
    "    return merged_df['ID'].iloc[res_indices[:]].to_list()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
