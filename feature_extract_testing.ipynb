{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import essentia.standard as es\n",
    "import numpy as np\n",
    "from essentia import Pool\n",
    "\n",
    "class MelSpectrogramOpenL3:\n",
    "    def __init__(self, hop_time):\n",
    "        self.hop_time = hop_time\n",
    "\n",
    "        self.sr = 48000\n",
    "        self.n_mels = 128\n",
    "        self.frame_size = 2048\n",
    "        self.hop_size = 242\n",
    "        self.a_min = 1e-10\n",
    "        self.d_range = 80\n",
    "        self.db_ref = 1.0\n",
    "\n",
    "        self.patch_samples = int(1 * self.sr)\n",
    "        self.hop_samples = int(self.hop_time * self.sr)\n",
    "\n",
    "        self.w = es.Windowing(\n",
    "            size=self.frame_size,\n",
    "            normalized=False,\n",
    "        )\n",
    "        self.s = es.Spectrum(size=self.frame_size)\n",
    "        self.mb = es.MelBands(\n",
    "            highFrequencyBound=self.sr / 2,\n",
    "            inputSize=self.frame_size // 2 + 1,\n",
    "            log=False,\n",
    "            lowFrequencyBound=0,\n",
    "            normalize=\"unit_tri\",\n",
    "            numberBands=self.n_mels,\n",
    "            sampleRate=self.sr,\n",
    "            type=\"magnitude\",\n",
    "            warpingFormula=\"slaneyMel\",\n",
    "            weighting=\"linear\",\n",
    "        )\n",
    "\n",
    "    def compute(self, audio_file):\n",
    "        audio = es.MonoLoader(filename=audio_file, sampleRate=self.sr)()\n",
    "\n",
    "        batch = []\n",
    "        for audio_chunk in es.FrameGenerator(\n",
    "            audio, frameSize=self.patch_samples, hopSize=self.hop_samples\n",
    "        ):\n",
    "            melbands = np.array(\n",
    "                [\n",
    "                    self.mb(self.s(self.w(frame)))\n",
    "                    for frame in es.FrameGenerator(\n",
    "                        audio_chunk,\n",
    "                        frameSize=self.frame_size,\n",
    "                        hopSize=self.hop_size,\n",
    "                        validFrameThresholdRatio=0.5,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            melbands = 10.0 * np.log10(np.maximum(self.a_min, melbands))\n",
    "            melbands -= 10.0 * np.log10(np.maximum(self.a_min, self.db_ref))\n",
    "            melbands = np.maximum(melbands, melbands.max() - self.d_range)\n",
    "            melbands -= np.max(melbands)\n",
    "\n",
    "            batch.append(melbands.copy())\n",
    "        return np.vstack(batch)\n",
    "\n",
    "\n",
    "class EmbeddingsOpenL3:\n",
    "    def __init__(self, graph_path, hop_time=1, batch_size=60, melbands=128):\n",
    "        self.hop_time = hop_time\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.graph_path = Path(graph_path)\n",
    "\n",
    "        self.x_size = 199\n",
    "        self.y_size = melbands\n",
    "        self.squeeze = False\n",
    "\n",
    "        self.permutation = [0, 3, 2, 1]\n",
    "\n",
    "        self.input_layer = \"melspectrogram\"\n",
    "        self.output_layer = \"embeddings\"\n",
    "\n",
    "        self.mel_extractor = MelSpectrogramOpenL3(hop_time=self.hop_time)\n",
    "\n",
    "        self.model = es.TensorflowPredict(\n",
    "            graphFilename=str(self.graph_path),\n",
    "            inputs=[self.input_layer],\n",
    "            outputs=[self.output_layer],\n",
    "            squeeze=self.squeeze,\n",
    "        )\n",
    "\n",
    "    def compute(self, audio_file):\n",
    "        mel_spectrogram = self.mel_extractor.compute(audio_file)\n",
    "        # in OpenL3 the hop size is computed in the feature extraction level\n",
    "\n",
    "        hop_size_samples = self.x_size\n",
    "\n",
    "        batch = self.__melspectrogram_to_batch(mel_spectrogram, hop_size_samples)\n",
    "\n",
    "        pool = Pool()\n",
    "        embeddings = []\n",
    "        nbatches = int(np.ceil(batch.shape[0] / self.batch_size))\n",
    "        for i in range(nbatches):\n",
    "            start = i * self.batch_size\n",
    "            end = min(batch.shape[0], (i + 1) * self.batch_size)\n",
    "            pool.set(self.input_layer, batch[start:end])\n",
    "            out_pool = self.model(pool)\n",
    "            embeddings.append(out_pool[self.output_layer].squeeze())\n",
    "\n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "    def __melspectrogram_to_batch(self, melspectrogram, hop_time):\n",
    "        npatches = int(np.ceil((melspectrogram.shape[0] - self.x_size) / hop_time) + 1)\n",
    "        batch = np.zeros([npatches, self.x_size, self.y_size], dtype=\"float32\")\n",
    "        for i in range(npatches):\n",
    "            last_frame = min(i * hop_time + self.x_size, melspectrogram.shape[0])\n",
    "            first_frame = i * hop_time\n",
    "            data_size = last_frame - first_frame\n",
    "\n",
    "            # the last patch may be empty, remove it and exit the loop\n",
    "            if data_size <= 0:\n",
    "                batch = np.delete(batch, i, axis=0)\n",
    "                break\n",
    "            else:\n",
    "                batch[i, :data_size] = melspectrogram[first_frame:last_frame]\n",
    "\n",
    "        batch = np.expand_dims(batch, 1)\n",
    "        batch = es.TensorTranspose(permutation=self.permutation)(batch)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from essentia.standard import MonoLoader, TensorflowPredictEffnetDiscogs, TensorflowPredict2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_django = pd.read_csv('data/songs_db.csv')\n",
    "df_features = pd.read_csv('data/song_dataset_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_songs = pd.read_csv('data/processed_songs.csv')\n",
    "df_to_extract = df_django[~df_django['song name'].isin(processed_songs['song name'])]\n",
    "audio_file_list = df_to_extract['file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/weights_metadata.json') as json_file:\n",
    "    model_weights_metadata = json.load(json_file)\n",
    "json_file.close()\n",
    "path = \"data/all_classifiers_and_metadata/\"\n",
    "song_path = 'media/'\n",
    "embedding_model_weights_l3 = \"data/all_classifiers_and_metadata/openl3-music-mel128-emb512-3.pb\"\n",
    "embedding_model_weights_dsg = \"data/all_classifiers_and_metadata/discogs-effnet-bs64-1.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(all_songs):\n",
    "    column_labels = ['song name']\n",
    "    rows = []\n",
    "    flag = True\n",
    "\n",
    "    for song in all_songs:\n",
    "        extractor = EmbeddingsOpenL3(embedding_model_weights_l3)\n",
    "        embeddings_l3 = extractor.compute(song_path + song)\n",
    "\n",
    "        audio = MonoLoader(filename=song_path+song, sampleRate=44100, resampleQuality=4)()\n",
    "        embedding_model = TensorflowPredictEffnetDiscogs(graphFilename=embedding_model_weights_dsg, output=\"PartitionedCall:1\")\n",
    "        embeddings_dsg = embedding_model(audio)\n",
    "\n",
    "        classification_models = {}\n",
    "        for key in model_weights_metadata:\n",
    "            model_type = model_weights_metadata[key][0]\n",
    "            file_name = model_weights_metadata[key][1]\n",
    "\n",
    "            weight_file = path + file_name + \".pb\"\n",
    "            mdata_file = path + file_name + \".json\"\n",
    "\n",
    "            metadata = json.load(open(mdata_file, 'r'))\n",
    "            input_ = metadata['schema']['inputs'][0]['name']\n",
    "            output = metadata['schema']['outputs'][0]['name']\n",
    "            classes = metadata['classes']\n",
    "\n",
    "            model = TensorflowPredict2D(graphFilename=weight_file, output=output, input=input_)\n",
    "            \n",
    "            classification_models[key] = [model, model_type, classes]\n",
    "            \n",
    "        scores = [df_to_extract[df_to_extract['file_path'] == song]['song name'].values[0]]\n",
    "\n",
    "        for key in classification_models:\n",
    "            model = classification_models[key][0]\n",
    "            model_type = classification_models[key][1]\n",
    "            classes = classification_models[key][2]\n",
    "\n",
    "            if model_type == \"openl3\":\n",
    "                predictions = np.mean(model(embeddings_l3), axis=0)\n",
    "            else:\n",
    "                predictions = np.mean(model(embeddings_dsg), axis=0)\n",
    "\n",
    "            if flag:\n",
    "                for i in range(0, len(predictions)):\n",
    "                    label = str(key) + \"_\" + str(classes[i])\n",
    "                    column_labels.append(label)\n",
    "        \n",
    "            for i in range(0, len(predictions)):\n",
    "                scores.append(predictions[i])\n",
    "                \n",
    "        flag = False\n",
    "        rows.append(scores)\n",
    "    return column_labels, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/openl3-music-mel128-emb512-3.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/discogs-effnet-bs64-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/danceability-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_acoustic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_aggressive-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_electronic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_happy-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_party-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_relaxed-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_sad-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/tonal_atonal-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/gender-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/voice_instrumental-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/engagement_regression-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/nsynth_reverb-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_instrument-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_genre-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_top50tags-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/danceability-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_acoustic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_aggressive-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_electronic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_happy-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_party-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_relaxed-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_sad-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/tonal_atonal-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/gender-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/voice_instrumental-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/engagement_regression-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/nsynth_reverb-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_instrument-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_genre-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_top50tags-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/openl3-music-mel128-emb512-3.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/discogs-effnet-bs64-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/danceability-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_acoustic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_aggressive-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_electronic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_happy-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_party-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_relaxed-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_sad-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/tonal_atonal-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/gender-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/voice_instrumental-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/engagement_regression-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/nsynth_reverb-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_instrument-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_genre-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_top50tags-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/danceability-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_acoustic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_aggressive-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_electronic-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_happy-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_party-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_relaxed-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mood_sad-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/tonal_atonal-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/gender-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/voice_instrumental-openl3-music-mel128-emb512-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/engagement_regression-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/nsynth_reverb-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_instrument-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_genre-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `data/all_classifiers_and_metadata/mtg_jamendo_top50tags-discogs-effnet-1.pb`\n"
     ]
    }
   ],
   "source": [
    "column_labels, rows = extract_all_features(audio_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(rows, columns=column_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_to_drop = [  'Genre_experimental', 'Genre_alternative', 'Genre_soundtrack',  'Genre_newage', 'Genre_psychedelic', 'Genre_world', 'Genre_singersongwriter', \n",
    "'Genre_minimal', 'Genre_progressive', 'Genre_contemporary', 'Genre_grunge', 'Genre_rnb', 'Genre_dance', 'Genre_idm', 'Genre_90s', 'Genre_soul', 'Genre_chanson', \n",
    "'Genre_60s', 'Genre_newwave', 'Genre_worldfusion', 'Genre_celtic', 'Genre_alternativerock', 'Genre_electronica', 'Genre_improvisation', 'Genre_80s', \n",
    "'Genre_edm', 'Genre_latin', 'Genre_hard','Genre_70s', 'Genre_swing', 'Genre_bossanova', 'Genre_eurodance']\n",
    "\n",
    "tags_to_drop = [  'Tag_energetic', 'Tag_trance', 'Tag_dance',  'Tag_happy', 'Tag_experimental', 'Tag_soundtrack', 'Tag_alternative', \n",
    "'Tag_world', 'Tag_lounge', 'Tag_voice', 'Tag_computer']\n",
    "\n",
    "instruments_to_drop = ['Instrument_bell', 'Instrument_bongo', 'Instrument_clarinet', 'Instrument_pad', 'Instrument_voice',\n",
    "        'Instrument_oboe', 'Instrument_rhodes',  'Instrument_computer',\n",
    "        'Instrument_horn', 'Instrument_viola', 'Instrument_sampler']\n",
    "\n",
    "other_columns_to_drop = ['danceability_not_danceable', 'mood_acoustic_non_acoustic', 'mood_aggressive_not_aggressive', 'mood_electronic_non_electronic', \n",
    "                         'mood_happy_non_happy', 'mood_party_non_party', 'mood_relaxed_non_relaxed', 'mood_sad_non_sad',  'tonal_atonal_atonal', 'voice_gender_male', \n",
    "                         'voice_instrumental_instrumental', 'Nsynth_Reverb_dry']\n",
    "\n",
    "rename_labels = {'danceability_danceable':'danceability', 'mood_acoustic_acoustic':'mood_acoustic', 'mood_aggressive_aggressive':'mood_aggressive', \n",
    "                 'mood_electronic_electronic':'mood_electronic', 'mood_happy_happy':'mood_happy', 'mood_party_party':'mood_party', 'mood_relaxed_relaxed':'mood_relaxed', \n",
    "                 'mood_sad_sad':'mood_sad', 'voice_instrumental_voice':'overall_voice', 'voice_gender_female':'voice_female', \n",
    "                 'tonal_atonal_tonal':'tonal','Engagement_engagement':'Engagement', 'Nsynth_Reverb_wet':'Reverb_wet'\n",
    "                 }\n",
    "\n",
    "all_columns_to_drop = genre_to_drop + tags_to_drop + instruments_to_drop + other_columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>mood_acoustic</th>\n",
       "      <th>mood_aggressive</th>\n",
       "      <th>mood_electronic</th>\n",
       "      <th>mood_happy</th>\n",
       "      <th>mood_party</th>\n",
       "      <th>mood_relaxed</th>\n",
       "      <th>mood_sad</th>\n",
       "      <th>tonal</th>\n",
       "      <th>...</th>\n",
       "      <th>Tag_electricpiano</th>\n",
       "      <th>Tag_guitar</th>\n",
       "      <th>Tag_keyboard</th>\n",
       "      <th>Tag_piano</th>\n",
       "      <th>Tag_strings</th>\n",
       "      <th>Tag_synthesizer</th>\n",
       "      <th>Tag_violin</th>\n",
       "      <th>Tag_emotional</th>\n",
       "      <th>Tag_film</th>\n",
       "      <th>Tag_relaxing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HITMAN 2 Soundtrack - Main Menu</td>\n",
       "      <td>0.162913</td>\n",
       "      <td>0.423373</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>0.490927</td>\n",
       "      <td>0.030353</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.985529</td>\n",
       "      <td>0.884160</td>\n",
       "      <td>0.570752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>0.140087</td>\n",
       "      <td>0.026664</td>\n",
       "      <td>0.175702</td>\n",
       "      <td>0.024543</td>\n",
       "      <td>0.034719</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.062103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HITMAN 2 Soundtrack - Results Screen</td>\n",
       "      <td>0.346552</td>\n",
       "      <td>0.143948</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>0.685958</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>0.157035</td>\n",
       "      <td>0.993870</td>\n",
       "      <td>0.948334</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.039162</td>\n",
       "      <td>0.019315</td>\n",
       "      <td>0.154389</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.150690</td>\n",
       "      <td>0.025710</td>\n",
       "      <td>0.036803</td>\n",
       "      <td>0.052089</td>\n",
       "      <td>0.071415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              song name  danceability  mood_acoustic   \n",
       "0       HITMAN 2 Soundtrack - Main Menu      0.162913       0.423373  \\\n",
       "1  HITMAN 2 Soundtrack - Results Screen      0.346552       0.143948   \n",
       "\n",
       "   mood_aggressive  mood_electronic  mood_happy  mood_party  mood_relaxed   \n",
       "0         0.025627         0.490927    0.030353    0.045771      0.985529  \\\n",
       "1         0.012917         0.685958    0.004539    0.157035      0.993870   \n",
       "\n",
       "   mood_sad     tonal  ...  Tag_electricpiano  Tag_guitar  Tag_keyboard   \n",
       "0  0.884160  0.570752  ...           0.008138    0.028909      0.012961  \\\n",
       "1  0.948334  0.512509  ...           0.014789    0.039162      0.019315   \n",
       "\n",
       "   Tag_piano  Tag_strings  Tag_synthesizer  Tag_violin  Tag_emotional   \n",
       "0   0.140087     0.026664         0.175702    0.024543       0.034719  \\\n",
       "1   0.154389     0.024648         0.150690    0.025710       0.036803   \n",
       "\n",
       "   Tag_film  Tag_relaxing  \n",
       "0  0.062800      0.062103  \n",
       "1  0.052089      0.071415  \n",
       "\n",
       "[2 rows x 137 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.drop(columns=all_columns_to_drop, inplace=True)\n",
    "new_df.rename(columns=rename_labels, inplace=True)\n",
    "new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking top Genres and Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_columns = [col for col in new_df.columns if col.startswith(\"Genre\")]\n",
    "tag_columns = [col for col in new_df.columns if col.startswith(\"Tag\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = new_df[genre_columns].T\n",
    "tag_data = new_df[tag_columns].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres, top_tags = [], []\n",
    "for col in genre_data.columns:\n",
    "    temp1 = genre_data[col].nlargest(3).index.to_list()\n",
    "    temp2 = tag_data[col].nlargest(5).index.to_list()\n",
    "    top_genres.append(temp1)\n",
    "    top_tags.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['top_genres'] = top_genres\n",
    "new_df['top_tags'] = top_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>mood_acoustic</th>\n",
       "      <th>mood_aggressive</th>\n",
       "      <th>mood_electronic</th>\n",
       "      <th>mood_happy</th>\n",
       "      <th>mood_party</th>\n",
       "      <th>mood_relaxed</th>\n",
       "      <th>mood_sad</th>\n",
       "      <th>tonal</th>\n",
       "      <th>...</th>\n",
       "      <th>Tag_keyboard</th>\n",
       "      <th>Tag_piano</th>\n",
       "      <th>Tag_strings</th>\n",
       "      <th>Tag_synthesizer</th>\n",
       "      <th>Tag_violin</th>\n",
       "      <th>Tag_emotional</th>\n",
       "      <th>Tag_film</th>\n",
       "      <th>Tag_relaxing</th>\n",
       "      <th>top_genres</th>\n",
       "      <th>top_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HITMAN 2 Soundtrack - Main Menu</td>\n",
       "      <td>0.162913</td>\n",
       "      <td>0.423373</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>0.490927</td>\n",
       "      <td>0.030353</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.985529</td>\n",
       "      <td>0.884160</td>\n",
       "      <td>0.570752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>0.140087</td>\n",
       "      <td>0.026664</td>\n",
       "      <td>0.175702</td>\n",
       "      <td>0.024543</td>\n",
       "      <td>0.034719</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.062103</td>\n",
       "      <td>[Genre_ambient, Genre_electronic, Genre_classi...</td>\n",
       "      <td>[Tag_ambient, Tag_electronic, Tag_classical, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HITMAN 2 Soundtrack - Results Screen</td>\n",
       "      <td>0.346552</td>\n",
       "      <td>0.143948</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>0.685958</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>0.157035</td>\n",
       "      <td>0.993870</td>\n",
       "      <td>0.948334</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019315</td>\n",
       "      <td>0.154389</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.150690</td>\n",
       "      <td>0.025710</td>\n",
       "      <td>0.036803</td>\n",
       "      <td>0.052089</td>\n",
       "      <td>0.071415</td>\n",
       "      <td>[Genre_ambient, Genre_electronic, Genre_classi...</td>\n",
       "      <td>[Tag_electronic, Tag_ambient, Tag_classical, T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              song name  danceability  mood_acoustic   \n",
       "0       HITMAN 2 Soundtrack - Main Menu      0.162913       0.423373  \\\n",
       "1  HITMAN 2 Soundtrack - Results Screen      0.346552       0.143948   \n",
       "\n",
       "   mood_aggressive  mood_electronic  mood_happy  mood_party  mood_relaxed   \n",
       "0         0.025627         0.490927    0.030353    0.045771      0.985529  \\\n",
       "1         0.012917         0.685958    0.004539    0.157035      0.993870   \n",
       "\n",
       "   mood_sad     tonal  ...  Tag_keyboard  Tag_piano  Tag_strings   \n",
       "0  0.884160  0.570752  ...      0.012961   0.140087     0.026664  \\\n",
       "1  0.948334  0.512509  ...      0.019315   0.154389     0.024648   \n",
       "\n",
       "   Tag_synthesizer  Tag_violin  Tag_emotional  Tag_film  Tag_relaxing   \n",
       "0         0.175702    0.024543       0.034719  0.062800      0.062103  \\\n",
       "1         0.150690    0.025710       0.036803  0.052089      0.071415   \n",
       "\n",
       "                                          top_genres   \n",
       "0  [Genre_ambient, Genre_electronic, Genre_classi...  \\\n",
       "1  [Genre_ambient, Genre_electronic, Genre_classi...   \n",
       "\n",
       "                                            top_tags  \n",
       "0  [Tag_ambient, Tag_electronic, Tag_classical, T...  \n",
       "1  [Tag_electronic, Tag_ambient, Tag_classical, T...  \n",
       "\n",
       "[2 rows x 139 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_exclusive_join = new_df['song name'][~new_df['song name'].isin(df_features['song name'])]\n",
    "new_entries = new_df[new_df['song name'].isin(right_exclusive_join)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataframe = pd.concat([df_features, new_entries], ignore_index=True)\n",
    "updated_dataframe.sort_values('song name', inplace=True)\n",
    "updated_dataframe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataframe['song name'].to_frame().to_csv('data/processed_songs.csv', index=False)\n",
    "updated_dataframe.to_csv('data/song_dataset_final.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pathlib import Path\n",
    "import essentia.standard as es\n",
    "from essentia.standard import TensorflowPredict2D\n",
    "import numpy as np\n",
    "from essentia import Pool\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpectrogramOpenL3:\n",
    "    def __init__(self, hop_time):\n",
    "        self.hop_time = hop_time\n",
    "\n",
    "        self.sr = 48000\n",
    "        self.n_mels = 128\n",
    "        self.frame_size = 2048\n",
    "        self.hop_size = 242\n",
    "        self.a_min = 1e-10\n",
    "        self.d_range = 80\n",
    "        self.db_ref = 1.0\n",
    "\n",
    "        self.patch_samples = int(1 * self.sr)\n",
    "        self.hop_samples = int(self.hop_time * self.sr)\n",
    "\n",
    "        self.w = es.Windowing(\n",
    "            size=self.frame_size,\n",
    "            normalized=False,\n",
    "        )\n",
    "        self.s = es.Spectrum(size=self.frame_size)\n",
    "        self.mb = es.MelBands(\n",
    "            highFrequencyBound=self.sr / 2,\n",
    "            inputSize=self.frame_size // 2 + 1,\n",
    "            log=False,\n",
    "            lowFrequencyBound=0,\n",
    "            normalize=\"unit_tri\",\n",
    "            numberBands=self.n_mels,\n",
    "            sampleRate=self.sr,\n",
    "            type=\"magnitude\",\n",
    "            warpingFormula=\"slaneyMel\",\n",
    "            weighting=\"linear\",\n",
    "        )\n",
    "\n",
    "    def compute(self, audio_file):\n",
    "        audio = es.MonoLoader(filename=audio_file, sampleRate=self.sr)()\n",
    "\n",
    "        batch = []\n",
    "        for audio_chunk in es.FrameGenerator(\n",
    "            audio, frameSize=self.patch_samples, hopSize=self.hop_samples\n",
    "        ):\n",
    "            melbands = np.array(\n",
    "                [\n",
    "                    self.mb(self.s(self.w(frame)))\n",
    "                    for frame in es.FrameGenerator(\n",
    "                        audio_chunk,\n",
    "                        frameSize=self.frame_size,\n",
    "                        hopSize=self.hop_size,\n",
    "                        validFrameThresholdRatio=0.5,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            melbands = 10.0 * np.log10(np.maximum(self.a_min, melbands))\n",
    "            melbands -= 10.0 * np.log10(np.maximum(self.a_min, self.db_ref))\n",
    "            melbands = np.maximum(melbands, melbands.max() - self.d_range)\n",
    "            melbands -= np.max(melbands)\n",
    "\n",
    "            batch.append(melbands.copy())\n",
    "        return np.vstack(batch)\n",
    "\n",
    "\n",
    "class EmbeddingsOpenL3:\n",
    "    def __init__(self, graph_path, hop_time=1, batch_size=60, melbands=128):\n",
    "        self.hop_time = hop_time\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.graph_path = Path(graph_path)\n",
    "\n",
    "        self.x_size = 199\n",
    "        self.y_size = melbands\n",
    "        self.squeeze = False\n",
    "\n",
    "        self.permutation = [0, 3, 2, 1]\n",
    "\n",
    "        self.input_layer = \"melspectrogram\"\n",
    "        self.output_layer = \"embeddings\"\n",
    "\n",
    "        self.mel_extractor = MelSpectrogramOpenL3(hop_time=self.hop_time)\n",
    "\n",
    "        self.model = es.TensorflowPredict(\n",
    "            graphFilename=str(self.graph_path),\n",
    "            inputs=[self.input_layer],\n",
    "            outputs=[self.output_layer],\n",
    "            squeeze=self.squeeze,\n",
    "        )\n",
    "\n",
    "    def compute(self, audio_file):\n",
    "        mel_spectrogram = self.mel_extractor.compute(audio_file)\n",
    "        # in OpenL3 the hop size is computed in the feature extraction level\n",
    "\n",
    "        hop_size_samples = self.x_size\n",
    "\n",
    "        batch = self.__melspectrogram_to_batch(mel_spectrogram, hop_size_samples)\n",
    "\n",
    "        pool = Pool()\n",
    "        embeddings = []\n",
    "        nbatches = int(np.ceil(batch.shape[0] / self.batch_size))\n",
    "        for i in range(nbatches):\n",
    "            start = i * self.batch_size\n",
    "            end = min(batch.shape[0], (i + 1) * self.batch_size)\n",
    "            pool.set(self.input_layer, batch[start:end])\n",
    "            out_pool = self.model(pool)\n",
    "            embeddings.append(out_pool[self.output_layer].squeeze())\n",
    "\n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "    def __melspectrogram_to_batch(self, melspectrogram, hop_time):\n",
    "        npatches = int(np.ceil((melspectrogram.shape[0] - self.x_size) / hop_time) + 1)\n",
    "        batch = np.zeros([npatches, self.x_size, self.y_size], dtype=\"float32\")\n",
    "        for i in range(npatches):\n",
    "            last_frame = min(i * hop_time + self.x_size, melspectrogram.shape[0])\n",
    "            first_frame = i * hop_time\n",
    "            data_size = last_frame - first_frame\n",
    "\n",
    "            # the last patch may be empty, remove it and exit the loop\n",
    "            if data_size <= 0:\n",
    "                batch = np.delete(batch, i, axis=0)\n",
    "                break\n",
    "            else:\n",
    "                batch[i, :data_size] = melspectrogram[first_frame:last_frame]\n",
    "\n",
    "        batch = np.expand_dims(batch, 1)\n",
    "        batch = es.TensorTranspose(permutation=self.permutation)(batch)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/openL3/\"\n",
    "song_path = 'media/'\n",
    "embedding_model_weights = \"data/openL3/openl3-music-mel128-emb512-3.pb\"\n",
    "\n",
    "def extract_features(all_songs, df_extract):\n",
    "    column_labels = ['song name']\n",
    "    rows = []\n",
    "    flag = True\n",
    "    with open('data/openL3/weights_metadata_openl3.json') as json_file:\n",
    "        model_weights_metadata = json.load(json_file)\n",
    "    for song in all_songs:\n",
    "        extractor = EmbeddingsOpenL3(embedding_model_weights)\n",
    "        embeddings = extractor.compute(song_path + song)\n",
    "\n",
    "        classification_models = {}\n",
    "        for key in model_weights_metadata:\n",
    "            value = model_weights_metadata[key]\n",
    "\n",
    "            weight_file = path + value + \".pb\"\n",
    "            mdata_file = path + value + \".json\"\n",
    "\n",
    "            metadata = json.load(open(mdata_file, 'r'))\n",
    "            input_ = metadata['schema']['inputs'][0]['name']\n",
    "            output = metadata['schema']['outputs'][0]['name']\n",
    "            classes = metadata['classes']\n",
    "\n",
    "            model = TensorflowPredict2D(graphFilename=weight_file, output=output, input=input_)\n",
    "            \n",
    "            classification_models[key] = [model, classes]\n",
    "        \n",
    "        #song_name = \".\".join(song.split('.')[:-1])\n",
    "        scores = [df_extract[df_extract['file_path'] == song]['song name'].values[0]]\n",
    "\n",
    "        for key in classification_models:\n",
    "            value = classification_models[key]\n",
    "            predictions = np.mean(value[0](embeddings), axis=0)\n",
    "\n",
    "            if flag:\n",
    "                for i in range(0, len(predictions)):\n",
    "                    label = str(key) + \"_\" + str(value[1][i])\n",
    "                    column_labels.append(label)\n",
    "        \n",
    "            for i in range(0, len(predictions)):\n",
    "                scores.append(predictions[i])\n",
    "\n",
    "        flag = False\n",
    "        rows.append(scores)\n",
    "    return column_labels, rows\n",
    "\n",
    "\n",
    "columns_to_drop = ['danceability_not_danceable', 'mood_acoustic_non_acoustic', 'mood_aggressive_not_aggressive', 'mood_electronic_non_electronic', 'mood_happy_non_happy', 'mood_party_non_party', 'mood_relaxed_non_relaxed', 'mood_sad_non_sad',  'tonal_atonal_atonal']\n",
    "rename_labels = {'danceability_danceable':'danceability', 'mood_acoustic_acoustic':'mood_acoustic', 'mood_aggressive_aggressive':'mood_aggressive', 'mood_electronic_electronic':'mood_electronic', \n",
    "                 'mood_happy_happy':'mood_happy', 'mood_party_party':'mood_party', 'mood_relaxed_relaxed':'mood_relaxed', 'mood_sad_sad':'mood_sad', \n",
    "                 'voice_instrumental_instrumental':'instrumental', 'voice_instrumental_voice':'voice', 'voice_gender_female':'voice_female', 'voice_gender_male':'voice_male',\n",
    "                 'tonal_atonal_tonal':'tonal'\n",
    "                 }\n",
    "\n",
    "def train_model():\n",
    "    df_django = pd.read_csv('data/songs_db.csv')\n",
    "    df_features = pd.read_csv('data/song_dataset_openl3.csv')\n",
    "\n",
    "    processed_songs = pd.read_csv('data/processed_songs.csv')\n",
    "    df_to_extract = df_django[~df_django['song name'].isin(processed_songs['song name'])]\n",
    "    audio_file_list = df_to_extract['file_path']\n",
    "\n",
    "    if len(audio_file_list)==0:\n",
    "        print(\"terminating\")\n",
    "        return\n",
    "    column_labels, rows = extract_features(audio_file_list, df_to_extract)\n",
    "\n",
    "    new_df = pd.DataFrame(rows, columns=column_labels)\n",
    "    new_df.drop(columns=columns_to_drop, inplace=True)\n",
    "    new_df.rename(columns=rename_labels, inplace=True)\n",
    "    right_exclusive_join = new_df['song name'][~new_df['song name'].isin(df_features['song name'])]\n",
    "    new_entries = new_df[new_df['song name'].isin(right_exclusive_join)]\n",
    "\n",
    "    updated_dataframe = pd.concat([df_features, new_entries], ignore_index=True)\n",
    "    updated_dataframe.sort_values('song name', inplace=True)\n",
    "    updated_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    updated_dataframe.to_csv('data/song_dataset_openl3.csv', index=False)\n",
    "    updated_dataframe['song name'].to_frame().to_csv('data/processed_songs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting Entries when model is deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.read_csv('data/processed_songs.csv')\n",
    "df_database = pd.read_csv('data/songs_db.csv')\n",
    "df_features = pd.read_csv('data/song_dataset_openl3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_delete = df_processed['song name'][~df_processed['song name'].isin(df_database['song name'])].index\n",
    "indices_to_delete2 = df_features['song name'][~df_features['song name'].isin(df_database['song name'])].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.drop(indices_to_delete, inplace=True)\n",
    "df_features.drop(indices_to_delete2, inplace=True)\n",
    "df_processed.reset_index(drop=True, inplace=True)\n",
    "df_features.reset_index(drop=True, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
